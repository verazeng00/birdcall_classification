{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/sagniksanyal/birdclef-2022-torchaudio-audiomentations-skimpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1 style = \"font-size:45px;font-family: Comic Sans MS;text-align: center;background-color:#800000;color:#FFFFFF\">Audio Albumentations</h1>\n",
    "\n",
    "<h3 style=\"font-family:Comic Sans MS\">The importance of albumentations in computer vision to improve performance is well known. Similar is the case when we are working with audio data.Augmentations and audio transforms play an imporatant role here also.In this notebook,I have tried to cover nearly all the possible albumentations that can be applied to audio data.The purpose is to provide the basic intuition of the audio albumentations,by listening the change in the audio for yourself and visualizing the waveform difference.<br>\n",
    "I have used both torchaudio transforms and the audiomentations library for covering all the albumentations.<br><br>\n",
    "    I hope you like this and it helps you with this competition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-11-30T06:10:58.383534Z",
     "iopub.status.busy": "2022-11-30T06:10:58.382202Z",
     "iopub.status.idle": "2022-11-30T06:11:09.821069Z",
     "shell.execute_reply": "2022-11-30T06:11:09.820017Z",
     "shell.execute_reply.started": "2022-11-30T06:10:58.383494Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install audiomentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-11-30T06:11:09.822667Z",
     "iopub.status.busy": "2022-11-30T06:11:09.822431Z",
     "iopub.status.idle": "2022-11-30T06:11:16.435778Z",
     "shell.execute_reply": "2022-11-30T06:11:16.434441Z",
     "shell.execute_reply.started": "2022-11-30T06:11:09.822644Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import torch\n",
    "import math\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import plotly.express as px\n",
    "import descartes\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "from IPython.display import Audio, display\n",
    "import sklearn\n",
    "import warnings\n",
    "import gc \n",
    "import torchaudio.functional as F\n",
    "import torchaudio.transforms as T\n",
    "warnings.filterwarnings('ignore')\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<h1 style = \"font-family: Comic Sans MS\">Some functions we will use</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-11-30T06:54:04.702165Z",
     "iopub.status.busy": "2022-11-30T06:54:04.699876Z",
     "iopub.status.idle": "2022-11-30T06:54:04.720652Z",
     "shell.execute_reply": "2022-11-30T06:54:04.719144Z",
     "shell.execute_reply.started": "2022-11-30T06:54:04.702129Z"
    }
   },
   "outputs": [],
   "source": [
    "def play_audio(waveform, sample_rate):\n",
    "    if type(waveform)!=numpy.ndarray:\n",
    "        waveform = waveform.numpy()\n",
    "    num_channels, num_frames = waveform.shape\n",
    "    if num_channels == 1:\n",
    "        display(Audio(waveform[0], rate=sample_rate))  # numpy into sound \n",
    "        # from IPython.display import Audio, display\n",
    "    elif num_channels == 2:\n",
    "        display(Audio((waveform[0], waveform[1]), rate=sample_rate))\n",
    "    else: \n",
    "        raise ValueError(\"Waveform with more than 2 channels are not supported.\")\n",
    "        \n",
    "def print_stats(waveform, sample_rate=None, src=None):\n",
    "    if src:\n",
    "        print(\"-\" * 10)\n",
    "        print(\"Source:\", src)\n",
    "        print(\"-\" * 10)\n",
    "    if sample_rate:\n",
    "        print(\"Sample Rate:\", sample_rate)\n",
    "        print(\"Shape:\", tuple(waveform.shape))\n",
    "        print(\"Dtype:\", waveform.dtype)\n",
    "        print(f\" - Max:     {waveform.max().item():6.3f}\")\n",
    "        print(f\" - Min:     {waveform.min().item():6.3f}\")\n",
    "        print(f\" - Mean:    {waveform.mean().item():6.3f}\")\n",
    "        print(f\" - Std Dev: {waveform.std().item():6.3f}\")\n",
    "        print()\n",
    "        print(waveform)\n",
    "        print()\n",
    "def plot_waveform(waveform, sample_rate, title=\"Waveform\", xlim=None, ylim=None):\n",
    "    if type(waveform)!=numpy.ndarray:\n",
    "        waveform = waveform.numpy()\n",
    "    num_channels, num_frames = waveform.shape\n",
    "    time_axis = torch.arange(0, num_frames) / sample_rate\n",
    "    figure, axes = plt.subplots(num_channels, figsize=(12,6))\n",
    "    if num_channels == 1:\n",
    "        axes = [axes]\n",
    "    for c in range(num_channels):\n",
    "        axes[c].plot(time_axis, waveform[c], linewidth=0.1,color = \"#A300F9\")  # default is line plot \n",
    "        axes[c].grid(True)\n",
    "        if num_channels > 1:\n",
    "            axes[c].set_ylabel(f'Channel {c+1}')\n",
    "        if xlim:\n",
    "            axes[c].set_xlim(xlim)\n",
    "        if ylim:\n",
    "            axes[c].set_ylim(ylim)\n",
    "    figure.suptitle(title)\n",
    "    plt.show(block=False)\n",
    "def plot_specgram(waveform, sample_rate, title=\"Spectrogram\", xlim=None):\n",
    "    waveform = waveform.numpy()\n",
    "\n",
    "    num_channels, num_frames = waveform.shape\n",
    "    time_axis = torch.arange(0, num_frames) / sample_rate\n",
    "\n",
    "    figure, axes = plt.subplots(num_channels, 1, figsize=(12,6))\n",
    "    if num_channels == 1:\n",
    "        axes = [axes]\n",
    "    for c in range(num_channels):\n",
    "        axes[c].specgram(waveform[c], Fs=sample_rate)\n",
    "        if num_channels > 1:\n",
    "            axes[c].set_ylabel(f'Channel {c+1}')\n",
    "        if xlim:\n",
    "            axes[c].set_xlim(xlim)\n",
    "    figure.suptitle(title)\n",
    "    plt.show(block=False)\n",
    "def plot_spectrogram(spec, title=None, ylabel='freq_bin', aspect='auto', xmax=None):\n",
    "    fig, axs = plt.subplots(1, 1)\n",
    "    axs.set_title(title or 'Spectrogram (db)')\n",
    "    axs.set_ylabel(ylabel)\n",
    "    axs.set_xlabel('frame')\n",
    "    im = axs.imshow(librosa.power_to_db(spec), origin='lower', aspect=aspect)\n",
    "    if xmax:\n",
    "        axs.set_xlim((0, xmax))\n",
    "    fig.colorbar(im, ax=axs)\n",
    "    plt.show(block=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1 style = \"font-family: Comic Sans MS\">Load The Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-30T06:11:16.437641Z",
     "iopub.status.busy": "2022-11-30T06:11:16.437347Z",
     "iopub.status.idle": "2022-11-30T06:11:16.887416Z",
     "shell.execute_reply": "2022-11-30T06:11:16.885879Z",
     "shell.execute_reply.started": "2022-11-30T06:11:16.437608Z"
    }
   },
   "outputs": [],
   "source": [
    "train_csv=pd.read_csv('../input/birdclef-2021/train_metadata.csv')\n",
    "train_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1 style = \"font-family: Comic Sans MS\">GETTING A FEW SAMPLES</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-30T06:20:54.728955Z",
     "iopub.status.busy": "2022-11-30T06:20:54.728447Z",
     "iopub.status.idle": "2022-11-30T06:20:54.746349Z",
     "shell.execute_reply": "2022-11-30T06:20:54.745146Z",
     "shell.execute_reply.started": "2022-11-30T06:20:54.728930Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_csv[train_csv['primary_label'] =='astfly'].sample(1, random_state = 33)\n",
    "# sample(*kargs)\n",
    "# n = 1: get one sample, \n",
    "# frac = 0.5: fraction = 0.5, \n",
    "# replace = True: allow to have sampling on the same row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-11-30T06:21:35.655051Z",
     "iopub.status.busy": "2022-11-30T06:21:35.654665Z",
     "iopub.status.idle": "2022-11-30T06:21:35.729053Z",
     "shell.execute_reply": "2022-11-30T06:21:35.727679Z",
     "shell.execute_reply.started": "2022-11-30T06:21:35.655020Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create Full Path so we can access data more easily\n",
    "base_dir = '../input/birdclef-2021/train_short_audio'\n",
    "train_csv['full_path'] = base_dir+ '/' + train_csv['primary_label'] + '/' + train_csv['filename']  \n",
    "# get the full path of bird song in train_short_audio folder\n",
    "\n",
    "# Now let's sample a fiew audio files\n",
    "astfly = train_csv[train_csv['primary_label'] == \"astfly\"].sample(1, random_state = 33)['full_path'].values[0]  \n",
    "# values: return array(['astfly'], dtype=object)\n",
    "casvir = train_csv[train_csv['primary_label'] == 'casvir'].sample(1, random_state = 33)['full_path'].values[0]\n",
    "subfly = train_csv[train_csv['primary_label'] == \"subfly\"].sample(1, random_state = 33)['full_path'].values[0]\n",
    "wilfly = train_csv[train_csv['primary_label'] == 'wilfly'].sample(1, random_state = 33)['full_path'].values[0]\n",
    "verdin = train_csv[train_csv['primary_label'] == 'verdin'].sample(1, random_state = 33)['full_path'].values[0]\n",
    "solsan = train_csv[train_csv['primary_label'] == 'solsan'].sample(1, random_state = 33)['full_path'].values[0]\n",
    "\n",
    "\n",
    "birds= [\"astfly\", \"casvir\", \"subfly\", \"wilfly\", \"verdin\",'solsan']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  # Loading audio data into Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-30T06:24:19.615369Z",
     "iopub.status.busy": "2022-11-30T06:24:19.615011Z",
     "iopub.status.idle": "2022-11-30T06:24:19.642885Z",
     "shell.execute_reply": "2022-11-30T06:24:19.641376Z",
     "shell.execute_reply.started": "2022-11-30T06:24:19.615344Z"
    }
   },
   "outputs": [],
   "source": [
    "waveform, sample_rate = torchaudio.load(astfly)\n",
    "print(waveform, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-30T06:33:04.799514Z",
     "iopub.status.busy": "2022-11-30T06:33:04.799191Z",
     "iopub.status.idle": "2022-11-30T06:33:04.839571Z",
     "shell.execute_reply": "2022-11-30T06:33:04.838266Z",
     "shell.execute_reply.started": "2022-11-30T06:33:04.799490Z"
    }
   },
   "outputs": [],
   "source": [
    "waveform, sample_rate = torchaudio.load(astfly)\n",
    "waveform.to(device)\n",
    "print_stats(waveform, sample_rate=sample_rate)\n",
    "play_audio(waveform, sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVING AUDIO TO FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saved the astfly audio (ogg format) that we loaded above in mp3 format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-30T06:35:00.441656Z",
     "iopub.status.busy": "2022-11-30T06:35:00.441326Z",
     "iopub.status.idle": "2022-11-30T06:35:00.665126Z",
     "shell.execute_reply": "2022-11-30T06:35:00.663674Z",
     "shell.execute_reply.started": "2022-11-30T06:35:00.441632Z"
    }
   },
   "outputs": [],
   "source": [
    "path = \"./audio.mp3\"\n",
    "torchaudio.save(path, waveform, sample_rate)  # save audio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-30T06:35:36.196200Z",
     "iopub.status.busy": "2022-11-30T06:35:36.195830Z",
     "iopub.status.idle": "2022-11-30T06:35:36.223504Z",
     "shell.execute_reply": "2022-11-30T06:35:36.221842Z",
     "shell.execute_reply.started": "2022-11-30T06:35:36.196173Z"
    }
   },
   "outputs": [],
   "source": [
    "waveform, sample_rate = torchaudio.load(astfly)\n",
    "waveform.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1 style = \"font-size:30px;font-family: Comic Sans MS;text-align:center\">RESAMPLE</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-30T06:39:32.482975Z",
     "iopub.status.busy": "2022-11-30T06:39:32.482527Z",
     "iopub.status.idle": "2022-11-30T06:39:32.495542Z",
     "shell.execute_reply": "2022-11-30T06:39:32.494273Z",
     "shell.execute_reply.started": "2022-11-30T06:39:32.482951Z"
    }
   },
   "outputs": [],
   "source": [
    "new_sample_rate = sample_rate/10\n",
    "# sample rate is the number of samples of a sound that are taken per second to represent the event digitally.\n",
    "transformed = torchaudio.transforms.Resample(sample_rate, new_sample_rate)(waveform)\n",
    "print(\"Shape of transformed waveform: {}\".format(transformed.size()))\n",
    "play_audio(transformed, new_sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-30T06:54:11.084627Z",
     "iopub.status.busy": "2022-11-30T06:54:11.083514Z",
     "iopub.status.idle": "2022-11-30T06:54:15.013233Z",
     "shell.execute_reply": "2022-11-30T06:54:15.011713Z",
     "shell.execute_reply.started": "2022-11-30T06:54:11.084600Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_waveform(waveform,sample_rate,title='Original')\n",
    "plot_waveform(transformed,new_sample_rate,title='resampled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1 style = \"font-size:30px;font-family: Comic Sans MS;text-align: center\"> APPLYING EFFECTS(SOX)</h1>\n",
    "<h3 style=\"font-family:Comic Sans MS\">\n",
    "1. Speed changing<br>\n",
    "2. Reverberation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-30T06:54:31.842516Z",
     "iopub.status.busy": "2022-11-30T06:54:31.842200Z",
     "iopub.status.idle": "2022-11-30T06:54:41.831724Z",
     "shell.execute_reply": "2022-11-30T06:54:41.830795Z",
     "shell.execute_reply.started": "2022-11-30T06:54:31.842493Z"
    }
   },
   "outputs": [],
   "source": [
    "waveform1, sample_rate1=torchaudio.load(astfly)\n",
    "waveform1.to(device)\n",
    "effects = [\n",
    "  [\"speed\", \"1.2\"],  # increase the speed\n",
    "                     # This only changes sample rate, so it is necessary to\n",
    "                     # add `rate` effect with original sample rate after this.\n",
    "  [\"rate\", f\"{sample_rate1}\"],\n",
    "  [\"reverb\", \"-w\"],  # Reverbration gives some dramatic feeling\n",
    "]\n",
    "waveform2, sample_rate2 = torchaudio.sox_effects.apply_effects_tensor(waveform1, sample_rate1, effects)\n",
    "waveform2.to(device)\n",
    "plot_waveform(waveform1, sample_rate1, title=\"Original\", xlim=(-.1, 3.2))  # the length is >= 10 but limit it into (-1. 3.2)\n",
    "plot_waveform(waveform2, sample_rate2, title=\"Effects Applied\", xlim=(-.1, 3.2))\n",
    "print_stats(waveform1, sample_rate=sample_rate1, src=\"Original\")\n",
    "print_stats(waveform2, sample_rate=sample_rate2, src=\"Effects Applied\")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-family:Comic Sans MS\">See the effect for yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-30T06:57:12.137129Z",
     "iopub.status.busy": "2022-11-30T06:57:12.136774Z",
     "iopub.status.idle": "2022-11-30T06:57:12.181358Z",
     "shell.execute_reply": "2022-11-30T06:57:12.179820Z",
     "shell.execute_reply.started": "2022-11-30T06:57:12.137104Z"
    }
   },
   "outputs": [],
   "source": [
    "play_audio(waveform1, sample_rate1)\n",
    "play_audio(waveform2, sample_rate2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1 style = \"font-size:30px;font-family: Comic Sans MS;text-align: center\">Adding background noise</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-family:Comic Sans MS\">To add background noise to audio data, you can simply add audio Tensor and noise Tensor. A commonly used way to adjust the intensity of noise is to change Signal-to-Noise Ratio (SNR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-11-30T07:10:32.357684Z",
     "iopub.status.busy": "2022-11-30T07:10:32.357358Z",
     "iopub.status.idle": "2022-11-30T07:10:32.365338Z",
     "shell.execute_reply": "2022-11-30T07:10:32.364176Z",
     "shell.execute_reply.started": "2022-11-30T07:10:32.357659Z"
    }
   },
   "outputs": [],
   "source": [
    "def _get_sample(path, resample=None):\n",
    "    effects = [\n",
    "      [\"remix\", \"1\"]\n",
    "    ]\n",
    "    if resample:\n",
    "        effects.append([\"rate\", f'{resample}'])\n",
    "    return torchaudio.sox_effects.apply_effects_file(path, effects=effects)\n",
    "\n",
    "def get_noise_sample(*, resample=None):\n",
    "    return _get_sample(casvir, resample=resample)  # cavir = /kaggle/input/birdclef-2021/train_short_audio/casvir/XC128912.ogg\n",
    "\n",
    "def get_speech_sample(*, resample=None):\n",
    "    return _get_sample(casvir, resample=resample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-30T07:10:34.657815Z",
     "iopub.status.busy": "2022-11-30T07:10:34.657103Z",
     "iopub.status.idle": "2022-11-30T07:10:47.208924Z",
     "shell.execute_reply": "2022-11-30T07:10:47.208241Z",
     "shell.execute_reply.started": "2022-11-30T07:10:34.657789Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_rate = 6000\n",
    "speech, _ = get_speech_sample(resample=sample_rate)\n",
    "speech.to(device)\n",
    "noise, _ = get_noise_sample(resample=sample_rate)  # waveform2, sample_rate2 \n",
    "noise.to(device)\n",
    "noise = noise[:, :speech.shape[1]]\n",
    "plot_waveform(noise, sample_rate, title=\"Background noise\")\n",
    "plot_specgram(noise, sample_rate, title=\"Background noise\")\n",
    "# how to read specgram: https://analyticsindiamag.com/hands-on-tutorial-on-visualizing-spectrograms-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-30T07:11:47.745930Z",
     "iopub.status.busy": "2022-11-30T07:11:47.745409Z",
     "iopub.status.idle": "2022-11-30T07:11:47.790842Z",
     "shell.execute_reply": "2022-11-30T07:11:47.789555Z",
     "shell.execute_reply.started": "2022-11-30T07:11:47.745892Z"
    }
   },
   "outputs": [],
   "source": [
    "play_audio(noise, sample_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-30T07:44:09.053727Z",
     "iopub.status.busy": "2022-11-30T07:44:09.053393Z",
     "iopub.status.idle": "2022-11-30T07:44:19.335631Z",
     "shell.execute_reply": "2022-11-30T07:44:19.334800Z",
     "shell.execute_reply.started": "2022-11-30T07:44:09.053702Z"
    }
   },
   "outputs": [],
   "source": [
    "speech_power = speech.norm(p=2)\n",
    "noise_power = noise.norm(p=2)\n",
    "for snr_db in [20]:\n",
    "    snr = math.exp(snr_db / 10)\n",
    "    scale = snr * noise_power / speech_power\n",
    "    noisy_speech = (scale * speech + noise) / 2\n",
    "    plot_waveform(noisy_speech, sample_rate1, title=f\"SNR: {snr_db} [dB]\")  # SNR: Signal-to-noise ratio\n",
    "    play_audio(noisy_speech, sample_rate1)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1 style = \"font-size:30px;font-family: Comic Sans MS\">SpecAugment</h1>\n",
    "<h4 style=\"font-family:Comic Sans MS\">SpecAugment is a popular augmentation technique applied on spectrogram.Torchaudio implements TimeStrech, TimeMasking and FrequencyMasking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1 style = \"font-size:30px;font-family: Comic Sans MS;text-align: center\">Time Masking</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-30T08:08:13.367366Z",
     "iopub.status.busy": "2022-11-30T08:08:13.367015Z",
     "iopub.status.idle": "2022-11-30T08:08:38.616869Z",
     "shell.execute_reply": "2022-11-30T08:08:38.615864Z",
     "shell.execute_reply.started": "2022-11-30T08:08:13.367341Z"
    }
   },
   "outputs": [],
   "source": [
    "waveform, sample_rate = torchaudio.load(subfly)\n",
    "waveform.to(device)\n",
    "print(waveform.shape)\n",
    "# play_audio(waveform, sample_rate)\n",
    "plot_waveform(waveform, sample_rate, title=\"Original\")\n",
    "plot_specgram(waveform, sample_rate, title=\"Original\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-30T07:58:00.601399Z",
     "iopub.status.busy": "2022-11-30T07:58:00.601042Z",
     "iopub.status.idle": "2022-11-30T07:58:01.611267Z",
     "shell.execute_reply": "2022-11-30T07:58:01.609615Z",
     "shell.execute_reply.started": "2022-11-30T07:58:00.601373Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.random.manual_seed(4)\n",
    "# 提取短时傅里叶特征 # get the unique frame??\n",
    "n_fft = 2048  # n_fft(int) 代表快速傅里叶变换的序列长度\n",
    "win_length = None # win_length(int) 代表窗口大小，默认等于 n_fft\n",
    "hop_length = 400  # hop_length(int) 代表相邻两个滑动窗口帧之间的距离，也即是帧移\n",
    "\n",
    "spectrogram = T.Spectrogram(\n",
    "    n_fft=n_fft,\n",
    "    win_length=win_length,\n",
    "    hop_length=hop_length\n",
    ")  # import torchaudio.transforms as T\n",
    "\n",
    "\n",
    "# Perform transformation\n",
    "spec = spectrogram(waveform) # torch.tensor, shape: [1, 1025, 8259])\n",
    " \n",
    "print(spec.shape)\n",
    "plot_spectrogram(spec[0], title=\"Original\")\n",
    "# [1025, 8259]: x = frame (8259), y = freq (1025), value = amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-30T07:58:15.966414Z",
     "iopub.status.busy": "2022-11-30T07:58:15.966015Z",
     "iopub.status.idle": "2022-11-30T07:58:16.937916Z",
     "shell.execute_reply": "2022-11-30T07:58:16.936559Z",
     "shell.execute_reply.started": "2022-11-30T07:58:15.966380Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "masking = T.TimeMasking(time_mask_param=1300) # max length of time mask; uniformly sample from frame axis\n",
    "spec = masking(spec)\n",
    "plot_spectrogram(spec[0], title=\"Masked along time axis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-30T07:59:32.879931Z",
     "iopub.status.busy": "2022-11-30T07:59:32.879580Z",
     "iopub.status.idle": "2022-11-30T07:59:48.846501Z",
     "shell.execute_reply": "2022-11-30T07:59:48.844561Z",
     "shell.execute_reply.started": "2022-11-30T07:59:32.879907Z"
    }
   },
   "outputs": [],
   "source": [
    "# Griffin Lim算法利用frame之间相位的约束来实现迭代收敛，可以在缺乏原始相位信息的基础上利用频谱重构出语音信号。\n",
    "griffin_lim = T.GriffinLim(\n",
    "    n_fft=n_fft,\n",
    "    win_length=win_length,\n",
    "    hop_length=hop_length,\n",
    ")\n",
    "waveform_n=griffin_lim(spec)\n",
    "plot_spectrogram(spec[0], title=\"Masked along time axis\")\n",
    "\n",
    "play_audio(waveform_n, sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1 style = \"font-size:30px;font-family: Comic Sans MS;text-align: center\">Frequency Masking</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-30T08:01:19.575725Z",
     "iopub.status.busy": "2022-11-30T08:01:19.574978Z",
     "iopub.status.idle": "2022-11-30T08:01:36.745871Z",
     "shell.execute_reply": "2022-11-30T08:01:36.744132Z",
     "shell.execute_reply.started": "2022-11-30T08:01:19.575686Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.random.manual_seed(4)\n",
    "waveform, sample_rate = torchaudio.load(subfly)\n",
    "waveform.to(device)\n",
    "n_fft = 2048\n",
    "win_length = None\n",
    "hop_length = 400\n",
    "\n",
    "spectrogram = T.Spectrogram(\n",
    "    n_fft=n_fft,\n",
    "    win_length=win_length,\n",
    "    hop_length=hop_length\n",
    ")\n",
    "# Perform transformation\n",
    "spec = spectrogram(waveform)\n",
    "plot_spectrogram(spec[0], title=\"Original\")\n",
    "masking = T.FrequencyMasking(freq_mask_param=1000)  # max length of frequency mask, uniformly chosed from frame bins \n",
    "spec = masking(spec)\n",
    "griffin_lim = T.GriffinLim(\n",
    "    n_fft=n_fft,\n",
    "    win_length=win_length,\n",
    "    hop_length=hop_length,\n",
    ")\n",
    "waveform_n=griffin_lim(spec)\n",
    "waveform.to(device)\n",
    "plot_spectrogram(spec[0], title=\"Masked along frequency axis\")\n",
    "play_audio(waveform, sample_rate)\n",
    "play_audio(waveform_n, sample_rate)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1 style = \"font-size:30px;font-family: Comic Sans MS;text-align: center\">FADE</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-30T08:13:44.246900Z",
     "iopub.status.busy": "2022-11-30T08:13:44.246563Z",
     "iopub.status.idle": "2022-11-30T08:13:51.119120Z",
     "shell.execute_reply": "2022-11-30T08:13:51.118270Z",
     "shell.execute_reply.started": "2022-11-30T08:13:44.246873Z"
    }
   },
   "outputs": [],
   "source": [
    "fade=T.Fade(fade_in_len=200, fade_out_len=100, fade_shape='linear')\n",
    "waveform, sample_rate = torchaudio.load(astfly)\n",
    "plot_waveform(waveform, sample_rate, title='original')\n",
    "play_audio(waveform, sample_rate)\n",
    "waveform1=fade(waveform)\n",
    "plot_waveform(waveform1, sample_rate, title='fade')\n",
    "play_audio(waveform1, sample_rate)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1 style = \"font-size:30px;font-family: Comic Sans MS;text-align: center\">VOLUME TRANSFORM</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T03:12:09.702522Z",
     "iopub.status.busy": "2022-03-22T03:12:09.701912Z",
     "iopub.status.idle": "2022-03-22T03:12:10.466547Z",
     "shell.execute_reply": "2022-03-22T03:12:10.465588Z",
     "shell.execute_reply.started": "2022-03-22T03:12:09.702482Z"
    }
   },
   "outputs": [],
   "source": [
    "vol=T.Vol(gain=29, gain_type='db')\n",
    "waveform, sample_rate = torchaudio.load(subfly)\n",
    "play_audio(waveform, sample_rate)\n",
    "waveform1=vol(waveform)\n",
    "play_audio(waveform1, sample_rate)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <h1 style = \"font-size:30px;font-family: Comic Sans MS\"> AUDIOMENTATIONS</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1 style = \"font-size:30px;font-family: Comic Sans MS;text-align: center\">Time Stretch & Clipping</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-30T09:04:06.687454Z",
     "iopub.status.busy": "2022-11-30T09:04:06.687041Z",
     "iopub.status.idle": "2022-11-30T09:04:09.467801Z",
     "shell.execute_reply": "2022-11-30T09:04:09.466741Z",
     "shell.execute_reply.started": "2022-11-30T09:04:06.687425Z"
    }
   },
   "outputs": [],
   "source": [
    "from audiomentations import TimeStretch # albumentation\n",
    "from audiomentations import Compose,ClippingDistortion\n",
    "augmenter = Compose(\n",
    "            [\n",
    "                ClippingDistortion(\n",
    "                    min_percentile_threshold=20, max_percentile_threshold=40, p=1.0\n",
    "                ),TimeStretch(min_rate=0.8, max_rate=0.9, leave_length_unchanged=False, p=1.0)\n",
    "            ]\n",
    "        )\n",
    "waveform, sample_rate = torchaudio.load(subfly)\n",
    "play_audio(waveform, sample_rate)\n",
    "waveform1 = augmenter(samples=waveform.numpy(), sample_rate=sample_rate)\n",
    "waveform1=torch.from_numpy(waveform1)\n",
    "play_audio(waveform1, sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1 style = \"font-size:30px;font-family: Comic Sans MS;text-align: center\">PITCH SHIFT & POLARITY INVERSION</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-30T09:04:16.179696Z",
     "iopub.status.busy": "2022-11-30T09:04:16.179354Z",
     "iopub.status.idle": "2022-11-30T09:05:09.265801Z",
     "shell.execute_reply": "2022-11-30T09:05:09.264666Z",
     "shell.execute_reply.started": "2022-11-30T09:04:16.179670Z"
    }
   },
   "outputs": [],
   "source": [
    "from audiomentations import PitchShift,PolarityInversion\n",
    "augmenter = Compose([PitchShift(min_semitones=-2, max_semitones=-1, p=1.0),PolarityInversion(p=1.0)])\n",
    "waveform, sample_rate = torchaudio.load(subfly)\n",
    "play_audio(waveform, sample_rate)\n",
    "waveform1 = augmenter(samples=waveform.numpy(), sample_rate=sample_rate)\n",
    "waveform1=torch.from_numpy(waveform1)\n",
    "play_audio(waveform1, sample_rate)\n",
    "plot_waveform(waveform, sample_rate, title='original')\n",
    "plot_waveform(waveform1, sample_rate, title='Augmented')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1 style = \"font-size:30px;font-family: Comic Sans MS;text-align: center\">FORWARD SHIFT</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T03:13:11.306074Z",
     "iopub.status.busy": "2022-03-22T03:13:11.305727Z",
     "iopub.status.idle": "2022-03-22T03:14:03.388624Z",
     "shell.execute_reply": "2022-03-22T03:14:03.387798Z",
     "shell.execute_reply.started": "2022-03-22T03:13:11.306037Z"
    }
   },
   "outputs": [],
   "source": [
    "from audiomentations import Shift\n",
    "forward_augmenter = Compose([Shift(min_fraction=0.5, max_fraction=0.5, p=1.0)])\n",
    "waveform, sample_rate = torchaudio.load(subfly)\n",
    "play_audio(waveform, sample_rate)\n",
    "waveform1 = forward_augmenter(samples=waveform.numpy(), sample_rate=sample_rate)\n",
    "waveform1=torch.from_numpy(waveform1)\n",
    "play_audio(waveform1, sample_rate)\n",
    "plot_waveform(waveform, sample_rate, title='original')\n",
    "plot_waveform(waveform1, sample_rate, title='Forward Shift')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1 style = \"font-size:30px;font-family: Comic Sans MS;text-align: center\">BACKWARD SHIFT</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T03:14:03.390214Z",
     "iopub.status.busy": "2022-03-22T03:14:03.389841Z",
     "iopub.status.idle": "2022-03-22T03:14:54.691533Z",
     "shell.execute_reply": "2022-03-22T03:14:54.690753Z",
     "shell.execute_reply.started": "2022-03-22T03:14:03.390185Z"
    }
   },
   "outputs": [],
   "source": [
    "backward_augmenter = Compose([Shift(min_fraction=-0.25, max_fraction=-0.25, p=1.0)])\n",
    "waveform, sample_rate = torchaudio.load(subfly)\n",
    "play_audio(waveform, sample_rate)\n",
    "waveform1 = backward_augmenter(samples=waveform.numpy(), sample_rate=sample_rate)\n",
    "waveform1=torch.from_numpy(waveform1)\n",
    "play_audio(waveform1, sample_rate)\n",
    "plot_waveform(waveform, sample_rate, title='original')\n",
    "plot_waveform(waveform1, sample_rate, title='Backward Shift')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skimpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-30T09:06:42.772359Z",
     "iopub.status.busy": "2022-11-30T09:06:42.771968Z",
     "iopub.status.idle": "2022-11-30T09:06:51.130654Z",
     "shell.execute_reply": "2022-11-30T09:06:51.129147Z",
     "shell.execute_reply.started": "2022-11-30T09:06:42.772334Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip -q install skimpy --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-30T09:06:56.375211Z",
     "iopub.status.busy": "2022-11-30T09:06:56.374843Z",
     "iopub.status.idle": "2022-11-30T09:06:56.384480Z",
     "shell.execute_reply": "2022-11-30T09:06:56.383120Z",
     "shell.execute_reply.started": "2022-11-30T09:06:56.375185Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from plotly.offline import init_notebook_mode,iplot\n",
    "init_notebook_mode(connected=True)\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import skimpy \n",
    "import plotly.express as px\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-30T09:05:47.372372Z",
     "iopub.status.busy": "2022-11-30T09:05:47.371931Z",
     "iopub.status.idle": "2022-11-30T09:05:47.621073Z",
     "shell.execute_reply": "2022-11-30T09:05:47.619551Z",
     "shell.execute_reply.started": "2022-11-30T09:05:47.372337Z"
    }
   },
   "outputs": [],
   "source": [
    "taxo = pd.read_csv(\"../input/birdclef-2022/eBird_Taxonomy_v2021.csv\")\n",
    "ss = pd.read_csv(\"../input/birdclef-2022/sample_submission.csv\")\n",
    "train = pd.read_csv(\"../input/birdclef-2022/train_metadata.csv\")\n",
    "test = pd.read_csv(\"../input/birdclef-2022/test.csv\")\n",
    "scored = pd.read_json(\"../input/birdclef-2022/scored_birds.json\")\n",
    "train_meta = pd.read_csv(\"../input/birdclef-2022/train_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-30T09:05:47.623424Z",
     "iopub.status.busy": "2022-11-30T09:05:47.622993Z",
     "iopub.status.idle": "2022-11-30T09:05:47.699562Z",
     "shell.execute_reply": "2022-11-30T09:05:47.698290Z",
     "shell.execute_reply.started": "2022-11-30T09:05:47.623390Z"
    }
   },
   "outputs": [],
   "source": [
    "skimpy.skim(taxo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T03:21:32.111807Z",
     "iopub.status.busy": "2022-03-22T03:21:32.111439Z",
     "iopub.status.idle": "2022-03-22T03:21:32.181403Z",
     "shell.execute_reply": "2022-03-22T03:21:32.180577Z",
     "shell.execute_reply.started": "2022-03-22T03:21:32.111777Z"
    }
   },
   "outputs": [],
   "source": [
    "skimpy.skim(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-30T09:07:24.339886Z",
     "iopub.status.busy": "2022-11-30T09:07:24.339569Z",
     "iopub.status.idle": "2022-11-30T09:07:24.421051Z",
     "shell.execute_reply": "2022-11-30T09:07:24.419829Z",
     "shell.execute_reply.started": "2022-11-30T09:07:24.339861Z"
    }
   },
   "outputs": [],
   "source": [
    "skimpy.skim(train_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-30T09:07:27.703559Z",
     "iopub.status.busy": "2022-11-30T09:07:27.703185Z",
     "iopub.status.idle": "2022-11-30T09:07:27.765008Z",
     "shell.execute_reply": "2022-11-30T09:07:27.763525Z",
     "shell.execute_reply.started": "2022-11-30T09:07:27.703533Z"
    }
   },
   "outputs": [],
   "source": [
    "skimpy.skim(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-30T09:07:32.836810Z",
     "iopub.status.busy": "2022-11-30T09:07:32.836467Z",
     "iopub.status.idle": "2022-11-30T09:07:34.479465Z",
     "shell.execute_reply": "2022-11-30T09:07:34.477987Z",
     "shell.execute_reply.started": "2022-11-30T09:07:32.836785Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = px.scatter_geo(train ,lat = \"latitude\", lon = \"longitude\", color = \"primary_label\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-30T09:08:01.674654Z",
     "iopub.status.busy": "2022-11-30T09:08:01.674285Z",
     "iopub.status.idle": "2022-11-30T09:08:01.971238Z",
     "shell.execute_reply": "2022-11-30T09:08:01.969744Z",
     "shell.execute_reply.started": "2022-11-30T09:08:01.674626Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = px.scatter_geo(data_frame = train , lat = \"latitude\", lon =\"longitude\", color = \"rating\", hover_data=[\"rating\", \"primary_label\"])\n",
    "fig.update_layout(\n",
    "    title=\"rating with primary_labels\",\n",
    "    font=dict(\n",
    "        family=\"Courier New, monospace\",\n",
    "        size=10,\n",
    "        color=\"RebeccaPurple\"\n",
    "    ),\n",
    "    margin=dict(l=40, r=40, t=100, b=80)\n",
    "\n",
    ")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
